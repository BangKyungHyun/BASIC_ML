import torch
import torch.nn.functional as F

# 목표 텐서 생성
target = torch.FloatTensor([[.1,.2,.3],
                            [.4,.5,.6],
                            [.7,.8,.9]])

# 랜덤값을 갖는 텐서 하나 생성
x = torch.rand_like(target)

################################################################################
# [중요] 텐서의 requires_grad 속성이 True가 되도록 설정해 주어야 함
# autograd 활성화 시키기
################################################################################
x.requires_grad = True

# 랜덤 생성한 텐서의 값을 출력
print("x =", x)
# x = tensor([[0.9335, 0.3228, 0.8134],
#        [0.4263, 0.2838, 0.1215],
#        [0.7253, 0.2697, 0.4487]], requires_grad=True)

# 두 텐서 사이의 비용값을 계산
loss = F.mse_loss(x, target)
print("loss =", loss)
# loss = tensor(0.1928, grad_fn=<MseLossBackward0>)

threshold = 1e-11   # 임계치
learning_rate = 1
iter_cnt = 0

################################################################################
# while 반복문을 사용하여 두 텐서 값의 차이가 threshold의 값보다 작아질 때 까지
# 미분 및 경사하강법을 반복 수행
################################################################################

while loss > threshold:

    iter_cnt += 1
    # backward 함수를 통해 편미분을 수행한다는 것인데 편미분을 통해 얻어진 기울기들이
    # x.grad에 자동 저장되고 이 값을 활용하여 경사하강법을 수행한다.
    # backward를 호출하기 위한 텐서의 크기는 스칼라이어야 함
    # 만약 스칼라가 아닌 경우에 backward를 호출하면 파이토치는 오류를 발생시킴

    loss.backward()                 # 기울기 계산
    x = x - learning_rate * x.grad  # 경사 기울기 값이 x.grad에 자동 저장

    # detach(분리하다) - 기존 Tensor에서 gradient 전파가 안되는 텐서 생성
    x.detach_()

    # autograd 활성화 시키기
    x.requires_grad_(True)

    loss = F.mse_loss(x, target)

    print('%d-th Loss : %.4e ' % (iter_cnt, loss))
    print("x = ",x )

# 1-th Loss : 5.6074e-02
# x =  tensor([[0.2326, 0.3354, 0.4494],
#         [0.5655, 0.4289, 0.8190],
#         [0.9244, 0.2406, 0.8481]], requires_grad=True)
# 2-th Loss : 3.3921e-02
# x =  tensor([[0.2032, 0.3053, 0.4162],
#         [0.5287, 0.4447, 0.7703],
#         [0.8745, 0.3649, 0.8597]], requires_grad=True)
# 3-th Loss : 2.0520e-02
# x =  tensor([[0.1802, 0.2819, 0.3904],
#         [0.5001, 0.4570, 0.7325],
#         [0.8357, 0.4616, 0.8686]], requires_grad=True)
# 4-th Loss : 1.2413e-02
# x =  tensor([[0.1624, 0.2637, 0.3703],
#         [0.4779, 0.4665, 0.7030],
#         [0.8056, 0.5368, 0.8756]], requires_grad=True)
# 5-th Loss : 7.5094e-03
# x =  tensor([[0.1485, 0.2495, 0.3547],
#         [0.4606, 0.4740, 0.6801],
#         [0.7821, 0.5953, 0.8810]], requires_grad=True)
# 6-th Loss : 4.5427e-03
# x =  tensor([[0.1377, 0.2385, 0.3425],
#         [0.4471, 0.4798, 0.6623],
#         [0.7639, 0.6408, 0.8852]], requires_grad=True)
# 7-th Loss : 2.7481e-03
# x =  tensor([[0.1294, 0.2300, 0.3331],
#         [0.4366, 0.4843, 0.6485],
#         [0.7497, 0.6762, 0.8885]], requires_grad=True)
# 8-th Loss : 1.6624e-03
# x =  tensor([[0.1228, 0.2233, 0.3257],
#         [0.4285, 0.4878, 0.6377],
#         [0.7386, 0.7037, 0.8911]], requires_grad=True)
# 9-th Loss : 1.0057e-03
# x =  tensor([[0.1178, 0.2181, 0.3200],
#         [0.4222, 0.4905, 0.6293],
#         [0.7300, 0.7251, 0.8931]], requires_grad=True)
# 10-th Loss : 6.0836e-04
# x =  tensor([[0.1138, 0.2141, 0.3156],
#         [0.4172, 0.4926, 0.6228],
#         [0.7234, 0.7417, 0.8946]], requires_grad=True)
# 11-th Loss : 3.6802e-04
# x =  tensor([[0.1107, 0.2110, 0.3121],
#         [0.4134, 0.4942, 0.6177],
#         [0.7182, 0.7547, 0.8958]], requires_grad=True)
# 12-th Loss : 2.2263e-04
# x =  tensor([[0.1084, 0.2085, 0.3094],
#         [0.4104, 0.4955, 0.6138],
#         [0.7141, 0.7647, 0.8967]], requires_grad=True)
# 13-th Loss : 1.3468e-04
# x =  tensor([[0.1065, 0.2066, 0.3073],
#         [0.4081, 0.4965, 0.6107],
#         [0.7110, 0.7726, 0.8975]], requires_grad=True)
# 14-th Loss : 8.1471e-05
# x =  tensor([[0.1051, 0.2052, 0.3057],
#         [0.4063, 0.4973, 0.6083],
#         [0.7086, 0.7787, 0.8980]], requires_grad=True)
# 15-th Loss : 4.9285e-05
# x =  tensor([[0.1039, 0.2040, 0.3044],
#         [0.4049, 0.4979, 0.6065],
#         [0.7067, 0.7834, 0.8985]], requires_grad=True)
# 16-th Loss : 2.9815e-05
# x =  tensor([[0.1031, 0.2031, 0.3034],
#         [0.4038, 0.4984, 0.6050],
#         [0.7052, 0.7871, 0.8988]], requires_grad=True)
# 17-th Loss : 1.8036e-05
# x =  tensor([[0.1024, 0.2024, 0.3027],
#         [0.4030, 0.4987, 0.6039],
#         [0.7040, 0.7900, 0.8991]], requires_grad=True)
# 18-th Loss : 1.0911e-05
# x =  tensor([[0.1019, 0.2019, 0.3021],
#         [0.4023, 0.4990, 0.6031],
#         [0.7031, 0.7922, 0.8993]], requires_grad=True)
# 19-th Loss : 6.6003e-06
# x =  tensor([[0.1014, 0.2015, 0.3016],
#         [0.4018, 0.4992, 0.6024],
#         [0.7024, 0.7939, 0.8994]], requires_grad=True)
# 20-th Loss : 3.9928e-06
# x =  tensor([[0.1011, 0.2011, 0.3013],
#         [0.4014, 0.4994, 0.6018],
#         [0.7019, 0.7953, 0.8996]], requires_grad=True)
# 21-th Loss : 2.4154e-06
# x =  tensor([[0.1009, 0.2009, 0.3010],
#         [0.4011, 0.4995, 0.6014],
#         [0.7015, 0.7963, 0.8997]], requires_grad=True)
# 22-th Loss : 1.4611e-06
# x =  tensor([[0.1007, 0.2007, 0.3008],
#         [0.4008, 0.4996, 0.6011],
#         [0.7011, 0.7971, 0.8997]], requires_grad=True)
# 23-th Loss : 8.8389e-07
# x =  tensor([[0.1005, 0.2005, 0.3006],
#         [0.4007, 0.4997, 0.6009],
#         [0.7009, 0.7978, 0.8998]], requires_grad=True)
# 24-th Loss : 5.3470e-07
# x =  tensor([[0.1004, 0.2004, 0.3005],
#         [0.4005, 0.4998, 0.6007],
#         [0.7007, 0.7983, 0.8998]], requires_grad=True)
# 25-th Loss : 3.2345e-07
# x =  tensor([[0.1003, 0.2003, 0.3004],
#         [0.4004, 0.4998, 0.6005],
#         [0.7005, 0.7987, 0.8999]], requires_grad=True)
# 26-th Loss : 1.9567e-07
# x =  tensor([[0.1002, 0.2003, 0.3003],
#         [0.4003, 0.4999, 0.6004],
#         [0.7004, 0.7990, 0.8999]], requires_grad=True)
# 27-th Loss : 1.1838e-07
# x =  tensor([[0.1002, 0.2002, 0.3002],
#         [0.4002, 0.4999, 0.6003],
#         [0.7003, 0.7992, 0.8999]], requires_grad=True)
# 28-th Loss : 7.1617e-08
# x =  tensor([[0.1001, 0.2002, 0.3002],
#         [0.4002, 0.4999, 0.6002],
#         [0.7003, 0.7994, 0.8999]], requires_grad=True)
# 29-th Loss : 4.3325e-08
# x =  tensor([[0.1001, 0.2001, 0.3001],
#         [0.4001, 0.4999, 0.6002],
#         [0.7002, 0.7995, 0.9000]], requires_grad=True)
# 30-th Loss : 2.6211e-08
# x =  tensor([[0.1001, 0.2001, 0.3001],
#         [0.4001, 0.5000, 0.6001],
#         [0.7002, 0.7996, 0.9000]], requires_grad=True)
# 31-th Loss : 1.5856e-08
# x =  tensor([[0.1001, 0.2001, 0.3001],
#         [0.4001, 0.5000, 0.6001],
#         [0.7001, 0.7997, 0.9000]], requires_grad=True)
# 32-th Loss : 9.5928e-09
# x =  tensor([[0.1001, 0.2001, 0.3001],
#         [0.4001, 0.5000, 0.6001],
#         [0.7001, 0.7998, 0.9000]], requires_grad=True)
# 33-th Loss : 5.8022e-09
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4001, 0.5000, 0.6001],
#         [0.7001, 0.7998, 0.9000]], requires_grad=True)
# 34-th Loss : 3.5098e-09
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6001],
#         [0.7001, 0.7999, 0.9000]], requires_grad=True)
# 35-th Loss : 2.1232e-09
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.7999, 0.9000]], requires_grad=True)
# 36-th Loss : 1.2840e-09
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.7999, 0.9000]], requires_grad=True)
# 37-th Loss : 7.7607e-10
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.7999, 0.9000]], requires_grad=True)
# 38-th Loss : 4.6985e-10
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.7999, 0.9000]], requires_grad=True)
# 39-th Loss : 2.8401e-10
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.8000, 0.9000]], requires_grad=True)
# 40-th Loss : 1.7190e-10
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.8000, 0.9000]], requires_grad=True)
# 41-th Loss : 1.0389e-10
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.8000, 0.9000]], requires_grad=True)
# 42-th Loss : 6.2815e-11
# x =  tensor([[0.1000, 0.2000, 0.3000],
#         [0.4000, 0.5000, 0.6000],
#         [0.7000, 0.8000, 0.9000]], requires_grad=True)
